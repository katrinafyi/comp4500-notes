<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
    
    <title>Single Page View</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/kognise/water.css@latest/dist/light.min.css">
    <!--<link rel="stylesheet" href="https://unpkg.com/mvp.css">-->
    <!--<link rel="stylesheet" href="https://latex.now.sh/style.css">-->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js"></script>
    <style>
      .katex { font-size: 1.1em; }
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
      div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
      ul.task-list{list-style: none;}
      pre > code.sourceCode { white-space: pre; position: relative; }
      pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
      pre > code.sourceCode > span:empty { height: 1.2em; }
      code.sourceCode > span { color: inherit; text-decoration: inherit; }
      div.sourceCode { margin: 1em 0; }
      pre.sourceCode { margin: 0; }
      @media screen {
      div.sourceCode { overflow: auto; }
      }
      @media print {
      pre > code.sourceCode { white-space: pre-wrap; }
      pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
      }
      pre.numberSource code
        { counter-reset: source-line 0; }
      pre.numberSource code > span
        { position: relative; left: -4em; counter-increment: source-line; }
      pre.numberSource code > span > a:first-child::before
        { content: counter(source-line);
          position: relative; left: -1em; text-align: right; vertical-align: baseline;
          border: none; display: inline-block;
          -webkit-touch-callout: none; -webkit-user-select: none;
          -khtml-user-select: none; -moz-user-select: none;
          -ms-user-select: none; user-select: none;
          padding: 0 4px; width: 4em;
          color: #aaaaaa;
        }
      pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
      div.sourceCode {   }
      @media screen {
        pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
      }
      code span.al { color: #ff0000; font-weight: bold; } /* Alert */
      code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
      code span.at { color: #7d9029; } /* Attribute */
      code span.bn { color: #40a070; } /* BaseN */
      code span.bu { } /* BuiltIn */
      code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
      code span.ch { color: #4070a0; } /* Char */
      code span.cn { color: #880000; } /* Constant */
      code span.co { color: #60a0b0; font-style: italic; } /* Comment */
      code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
      code span.do { color: #ba2121; font-style: italic; } /* Documentation */
      code span.dt { color: #902000; } /* DataType */
      code span.dv { color: #40a070; } /* DecVal */
      code span.er { color: #ff0000; font-weight: bold; } /* Error */
      code span.ex { } /* Extension */
      code span.fl { color: #40a070; } /* Float */
      code span.fu { color: #06287e; } /* Function */
      code span.im { } /* Import */
      code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
      code span.kw { color: #007020; font-weight: bold; } /* Keyword */
      code span.op { color: #666666; } /* Operator */
      code span.ot { color: #007020; } /* Other */
      code span.pp { color: #bc7a00; } /* Preprocessor */
      code span.sc { color: #4070a0; } /* SpecialChar */
      code span.ss { color: #bb6688; } /* SpecialString */
      code span.st { color: #4070a0; } /* String */
      code span.va { color: #19177c; } /* Variable */
      code span.vs { color: #4070a0; } /* VerbatimString */
      code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
      .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    </style>
    <!--<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>-->
    <script>document.addEventListener("DOMContentLoaded", function () {
    var mathElements = document.getElementsByClassName("math");
    var macros = [];
    /*
    const BATCH_SIZE = 100;
    var i = 0;
    while (i < mathElements.length) {
      const start = i;
      setTimeout(() => {
        for (var j = 0; j < BATCH_SIZE; j++) {
          const i = start + j;
          if (i >= mathElements.length) break;

          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }, 0);
      i += BATCH_SIZE;
    }
    */
    
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
      katex.render(texText.data, mathElements[i], {
        displayMode: mathElements[i].classList.contains('display'),
        throwOnError: false,
        macros: macros,
        fleqn: false
      });
    }}
    
    });
    </script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" />
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <h1>Single Page View</h1>

    
<small>This is an automatically generated page containing everything in a single view.</small>



<article>
<h2>Table of Contents</h2>
<nav class="toc">
                <ol>
                    
                    <li><a href="#comp4500-advanced-algorithms-data-structures">COMP4500 — Advanced Algorithms & Data Structures</a>
            		</li>

                    <li><a href="#introduction-and-background">Introduction and Background</a>
            
                <ol>
                    
                    <li><a href="#motivation">Motivation</a>
            		</li>
                </ol>
            		</li>

                    <li><a href="#running-time-analysis-and-asymptotic-notation">Running Time Analysis and Asymptotic Notation</a>
            
                <ol>
                    
                    <li><a href="#asymptotic-notation">Asymptotic Notation</a>
            		</li>
                </ol>
            		</li>

                    <li><a href="#recursive-functions">Recursive functions</a>
            
                <ol>
                    
                    <li><a href="#recurrences">Recurrences</a>
            		</li>

                    <li><a href="#substitution">Substitution</a>
            		</li>

                    <li><a href="#iteration">Iteration</a>
            		</li>

                    <li><a href="#master-method">Master method</a>
            		</li>
                </ol>
            		</li>

                    <li><a href="#lecture-3-graphs">Lecture 3 — Graphs</a>
            
                <ol>
                    
                    <li><a href="#undirected-graph">Undirected graph</a>
            		</li>

                    <li><a href="#directed-graph">Directed graph</a>
            		</li>

                    <li><a href="#weights">Weights</a>
            		</li>

                    <li><a href="#terminology">Terminology</a>
            		</li>

                    <li><a href="#types-of-graphs">Types of graphs</a>
            		</li>

                    <li><a href="#representations">Representations</a>
            		</li>

                    <li><a href="#graph-traversal-algorithms">Graph traversal algorithms</a>
            		</li>

                    <li><a href="#topological-sort">Topological sort</a>
            		</li>
                </ol>
            		</li>

                    <li><a href="#lecture-4-graphs-2">Lecture 4 — Graphs 2</a>
            
                <ol>
                    
                    <li><a href="#minimum-spanning-tree">Minimum Spanning Tree</a>
            		</li>

                    <li><a href="#generic-constructive-algorithm">Generic Constructive Algorithm</a>
            		</li>

                    <li><a href="#prims-algorithm">Prim’s Algorithm</a>
            		</li>

                    <li><a href="#kruskals-algorithm">Kruskal’s Algorithm</a>
            		</li>
                </ol>
            		</li>

                    <li><a href="#lecture-5-graph-algorithms-2">Lecture 5 — Graph Algorithms 2</a>
            
                <ol>
                    
                    <li><a href="#single-source-shortest-path">Single source shortest path</a>
            		</li>

                    <li><a href="#non-negative-weights">Non-negative weights</a>
            		</li>

                    <li><a href="#dijkstras-algorithm">Dijkstra’s algorithm</a>
            		</li>

                    <li><a href="#negative-weights">Negative weights</a>
            		</li>

                    <li><a href="#bellman-ford">Bellman-Ford</a>
            		</li>

                    <li><a href="#priority-first-search">Priority first search</a>
            		</li>
                </ol>
            		</li>
                </ol>
            </nav>
</article>

<h1>Lecture 1</h1>

  <!--
<header id="title-block-header">
<h1 class="title">Lecture 1 — Introduction</h1>
<p class="author">Kenton Lam</p>
</header>
-->


<h1 id="comp4500-advanced-algorithms-data-structures">COMP4500 — Advanced Algorithms &amp; Data Structures</h1>
<p>Lectured by Ahmad Abdel-Hafez. Currently works full-time as a data scientist. First time teaching at UQ. Not a mathematician.</p>
<h1 id="introduction-and-background">Introduction and Background</h1>
<h2 id="motivation">Motivation</h2>
<ul>
<li><em>Creating</em> more efficient algorithms.</li>
<li><em>Justifying</em> choice of algorithms using theory.</li>
<li><em>Improving</em> problem solving skills.</li>
<li>This is a prerequisite for a job at Google, Amazon, Oracle, etc.</li>
</ul>
<h3 id="research-areas">Research Areas</h3>
<p>These areas are currently being researched and developed:</p>
<ul>
<li>distributed/parallel algorithms,</li>
<li>neural networks/pattern recognition,</li>
<li>bioinformatics, and</li>
<li>quantum computing.</li>
</ul>
<h3 id="outline">Outline</h3>
<ul>
<li>Background and asymptotic notation.</li>
<li>Recurrences, divide and conquer.</li>
<li>Graph algorithms (3 weeks).</li>
<li>Dynamic programming (2 weeks). <strong>Assignment 1 published.</strong></li>
<li><strong>Midsemester exam.</strong></li>
<li><strong>Assignment 2 published.</strong></li>
<li>Greedy algorithms.</li>
<li>Amortised analysis.</li>
<li>Complexity classes.</li>
<li>Randomised algorithms.</li>
</ul>
<h3 id="other">Other</h3>
<ul>
<li>Textbook is Cormen at al. (CLRS).</li>
<li>Tutorials start in Week 2.</li>
<li>Piazza will be used.</li>
<li>Consultation with lecturer can be organised by email.</li>
</ul>
<h1 id="running-time-analysis-and-asymptotic-notation">Running Time Analysis and Asymptotic Notation</h1>
<ul>
<li><p>An <strong>algorithm</strong> is a well-defined computation procedure which takes some values as <em>input</em> and produces some value as <em>output</em>.</p></li>
<li><p>As an example, <em>insertion sort</em> is an algorithm taking an array as input and returning a sorted array. It works by building the sorted array from left to right by inserting the next value in its sorted position.</p></li>
<li><p><em>Loop invariants</em> can be used to prove an algorithm is correct.</p></li>
<li><p><strong>Execution time</strong> depends on input size and the input itself. Generally, we want an upper bound on the execution time.</p>
<ul>
<li>There are <em>worst</em>, <em>average</em>, and <em>best</em> case execution times. Average case is the average over all inputs, weighted by the probability of that input.</li>
</ul></li>
<li><p>For example, insertion sort requires <span class="math inline">n(n-1)/2</span> comparisons in the worst case and <span class="math inline">n-1</span> in the best case.</p></li>
</ul>
<h2 id="asymptotic-notation">Asymptotic Notation</h2>
<ul>
<li><p>For sufficiently large <span class="math inline">n</span>, the constants are negligible.</p></li>
<li><p>Example: <span class="math inline">2n^2 \in O(n^3 - n^2)</span>.</p></li>
<li><p>Theorems:</p>
<ul>
<li>If <span class="math inline">f \in O(g)</span>, then <span class="math inline">g + f \in \Theta(g)</span>. If <span class="math inline">f</span> grows no larger than <span class="math inline">g</span>, it doesn’t affect the big-<span class="math inline">\Theta</span> bound of <span class="math inline">g</span>.</li>
<li>If <span class="math inline">k &gt; 0</span>, then <span class="math inline">k n^a \in \Theta(n^a)</span>.</li>
<li>If <span class="math inline">k &gt; 0</span> and <span class="math inline">0 \le a \le b</span>, then <span class="math inline">k n^a \in O(n^b)</span>.</li>
</ul></li>
<li><p><span class="math inline">f</span> is asymptotically non-negative if <span class="math inline">f(n) \ge 0</span> for <span class="math inline">n \ge n_0</span>.</p></li>
<li><p>Theorem: If <span class="math inline">f, g</span> are asymptotically non-negative and <span class="math inline">\lim_{n \to \infty} f(n)/g(n) = c</span>, then:</p>
<ul>
<li><span class="math inline">f(n) \in O(g(n))</span> if <span class="math inline">c &lt; \infty</span>,</li>
<li><span class="math inline">f(n) \in \Theta(g(n))</span> if <span class="math inline">0 &lt; c &lt; \infty</span>, and</li>
<li>$f(n) (g(n)) $ if <span class="math inline">c &gt; 0</span>.</li>
</ul></li>
</ul><h1>Lecture 2</h1>

  <!--
<header id="title-block-header">
<h1 class="title">Lecture 2 — Recurrences</h1>
<p class="author">Kenton Lam</p>
</header>
-->


<h1 id="recursive-functions">Recursive functions</h1>
<p>There are three strategies we can use:</p>
<ul>
<li>substitution, where we guess an answer and prove it satisfies the recurrence,</li>
<li>iteration, expanding into a sum and evaluating, and</li>
<li>master theorem which covers some particular cases.</li>
</ul>
<h3 id="divide-and-conquer-algorithms">Divide and conquer algorithms</h3>
<p>Recall merge sort, defined as <span class="math inline">\texttt{merge_sort}(A, p, r)</span>. This also uses a subroutine <span class="math inline">\texttt{merge}(A, p, q, r)</span> which merges the subarrays <span class="math inline">A[p,q]</span> and <span class="math inline">A[q+1, r]</span> into <span class="math inline">A[p, r]</span> (this algorithm is <span class="math inline">\Theta(n)</span> where <span class="math inline">n=r-p+1</span>).</p>
<p>The time complexity of merge sort is <span class="math inline">T(n) = 2T(n/2) + f(n)</span> with <span class="math inline">f(n) \in \Theta(n)</span>.</p>
<h2 id="recurrences">Recurrences</h2>
<p>To be well-defined, a recurrence relation needs a base case and recursive case(s) which converge towards that base case. Sometimes, we omit the base case and implicitly take it as <span class="math inline">T(n) = \Theta(1)</span> for <span class="math inline">n \le c</span>. This does not have a significant effect on the running time of the base case.</p>
<p>Consider a generic divide and conquer algorithm which</p>
<ul>
<li>takes input of size <span class="math inline">n</span>,</li>
<li>breaks it into <span class="math inline">a</span> parts, each of size <span class="math inline">n/b</span>,</li>
<li>takes <span class="math inline">D(n)</span> time to divide the problem in this way, and</li>
<li>takes <span class="math inline">C(n)</span> time to combine the subproblem results.</li>
</ul>
<p>This results in the following recurrence: <span class="math display">
T(n) = \begin{cases}
aT(n/b) + D(n) + C(n), &amp; n \ge c, \\ 
\Theta(1), &amp; n \le c.
\end{cases}
</span></p>
<h2 id="substitution">Substitution</h2>
<p><strong>Example:</strong> Consider <span class="math display">
T(n) = \begin{cases}
2, &amp; n=2,\\
2T(n/2) + n, &amp;n=2^k,
\end{cases}
</span> and we guess that <span class="math display">
T(n) = n \log_2 n.
</span> The base case is that <span class="math inline">T(2) = 2 = 2 \log_2(2)</span>. The inductive step is <span class="math display">
\begin{aligned}
T(n) = 2T(n/2)+n &amp;= 2(n/2)\log_2(n/2) + n \\ 
&amp;= n(\log_2 n - \log_22) + n \\ 
&amp;= n \log_2 n
\end{aligned}
</span> which is what we wanted to show.</p>
<p><strong>Example:</strong> As a more complicated example using <span class="math display">
T(n) =\begin{cases}
1, &amp; n=1, \\ 
2T(\lfloor n/2\rfloor) + n, &amp; n&gt;1.
\end{cases}
</span> We notice it resembles the earlier example and we guess that <span class="math inline">T(n) \in O(n \lg n)</span>. We need to prove this using the definition.</p>
<p>First, we need an <span class="math inline">n_0</span>. We can see that <span class="math inline">n_0=1</span> doesn’t work because <span class="math inline">T(1) = 1</span> which is not less than <span class="math inline">0</span>. Suppose <span class="math inline">n_0=2</span>, then for the cases which depend directly on <span class="math inline">T(1)</span>, we have <span class="math display">
\begin{aligned}
T(2)&amp; = 2T(1) + 2 = 4 \le c2 \lg 2\\
T(3)&amp; = 2T(1) + 3 = 5 \le c 2 \lg 2\\
\end{aligned}
</span> for some <span class="math inline">c \ge 2</span>.</p>
<p>Moving onto the induction, we assume that <span class="math inline">T(n) \le c n \lg n</span> for <span class="math inline">\lfloor n/2\rfloor</span> and we want prove this for the case of <span class="math inline">n</span>. Substituting, <span class="math display">
\begin{aligned}
T(n) = 2T(\lfloor n/2\rfloor) + n  
&amp;\le 2(c \lfloor n/2\rfloor \lg \lfloor n/2\rfloor) + n \\ 
&amp;\le c  n \lg \lfloor n/2\rfloor + n \\ 
&amp;=  c  n (\lg n - \lg 2) + n \\  
&amp;=  cn\lg n - cn\lg 2 + n \\ 
&amp;\le cn \lg n
\end{aligned}
</span> assuming <span class="math inline">c \ge 1</span> and <span class="math inline">n \ge 0</span>.</p>
<p><strong>Example:</strong> Guessing does not always work in this way. Consider, <span class="math display">
T(n) = T(\lfloor n/2 \rfloor) + T(\lceil n/2 \rceil) + 1
</span> and we guess that <span class="math inline">T(n) = O(n)</span> (which is actually correct). Trying to prove the inductive step, we get <span class="math display">
\begin{aligned}
T(n) = T(\lfloor n/2 \rfloor) + T(\lceil n/2 \rceil) + 1 
&amp;\le c(\lfloor n/2 \rfloor) + c(\lceil n/2 \rceil) + 1  \\ 
&amp;=cn+1 
\end{aligned}
</span> which is not <span class="math inline">\le cn</span>, so we cannot prove it this way! We can solve this problem by <em>strenghtening the guess</em>, via subtracting a lower order term. Specifically, we assume that <span class="math inline">T(n) \le cn-b</span> for <span class="math inline">b&gt;0</span>. This does not affect the asymptotic bound but with this stronger assumption, we are able to probe a stronger result.</p>
<p><strong>Note:</strong> In the inductive step, we need to be very precise. We need to prove that <span class="math inline">T(n) \le cn</span> very carefully, something like <span class="math inline">cn + n = O(n)</span> is not good enough.</p>
<h4 id="change-of-variables">Change of variables</h4>
<p>Consider <span class="math display">
T(n) = 2 T(\lfloor \sqrt n \rfloor) + \lg n.
</span> This looks hard, but one trick we can use for some more unfamiliar cases is changing the variables. We try <span class="math inline">m = \lg n</span> which means <span class="math inline">n = 2^m</span>. Making the change, <span class="math display">
T(2^m)=2T(2^{m/2}) + m \iff S(m) = 2S(m/2) + m
</span> where <span class="math inline">S(m) = T^(2^m)</span>. The <span class="math inline">S</span> expression looks familiar and we know the solution is <span class="math inline">S(m) \in \Theta(m \lg m)</span>. Changing back gives us <span class="math display">
T(n) = T(2^{m}) = S(m) = \Theta(m \lg m) = \Theta(\lg n \lg(\lg n)).
</span></p>
<h2 id="iteration">Iteration</h2>
<h2 id="master-method">Master method</h2>
<p>Suppose <span class="math inline">T</span> is of the form <span class="math display">
T(n) = aT(n/b) + f(n)
</span> where <span class="math inline">n/b</span> can also have a ceiling or floor. Then, we need to compare the work at each step, <span class="math inline">f(n)</span> with how many calls there are. Specifically,</p>
<ul>
<li><ol type="1">
<li>if <span class="math inline">n^{\log_b a}</span> is polynomially <em>larger</em> than <span class="math inline">f(n)</span>, then <span class="math inline">T(n) \in \Theta(n^{\log_ba})</span>,</li>
</ol></li>
<li><ol start="2" type="1">
<li>if <span class="math inline">n^{\log_b a}</span> is the same asymptotic <em>tight</em> bound as <span class="math inline">f(n)</span>, then <span class="math inline">T(n) \in \Theta(n^{\log_ba}\lg n)</span>, and</li>
</ol></li>
<li><ol start="3" type="1">
<li>if <span class="math inline">f(n)</span> is polynomially <em>larger</em> than <span class="math inline">n^{\log_ba}</span> and <span class="math inline">f(n)</span> is regular, then <span class="math inline">T(n) \in \Theta(f(n))</span>.</li>
</ol></li>
</ul>
<p>We say a function <span class="math inline">f</span> is <strong>polynomially larger than</strong> <span class="math inline">g</span> if <span class="math inline">f</span> is lower bounded by <span class="math inline">g</span> times some polynomial with degree <span class="math inline">\epsilon&gt;0</span>. That is, <span class="math display">
f(n) \in \Omega(g(n) \times n^\epsilon) \quad \text{where }\epsilon &gt; 0
</span> or equivalently, <span class="math display">
f(n) / g(n) \in \Omega(n^\epsilon).
</span> A function is <strong>regular</strong> if <span class="math inline">af(n/b)&lt; cf(n)</span> for <span class="math inline">c&lt;1</span>. This just ensures that the subproblems are decreasing in complexity.</p>
<p>Putting this together, we have these three cases:</p>
<ul>
<li><ol type="1">
<li><span class="math inline">f(n) \in O(n^{\log_{b}a-\epsilon})\implies T(n) \in \Theta(n^{\log_b a})</span>,</li>
</ol></li>
<li><ol start="2" type="1">
<li><span class="math inline">f(n) \in \Theta(n^{\log_ba})\implies T(n) \in \Theta(n^{\log_b a} \lg n)</span>, and</li>
</ol></li>
<li><ol start="3" type="1">
<li><span class="math inline">f(n) \in \Omega(n^{\log_ba+\epsilon})</span> and regularity <span class="math inline">\implies T(n) \in \Theta(f(n))</span>.</li>
</ol></li>
</ul>
<p><strong>Example:</strong> Consider merge sort from earlier with <span class="math inline">T(n) = 2 T(n/2) + f(n)</span> with <span class="math inline">f(n) \in \Theta(n)</span>. We compare <span class="math inline">f(n)</span> to <span class="math inline">n^{\log_22}=n</span> and we see they are asymptotically the same. As a result, this is case 2 and <span class="math inline">T(n) \in \Omega(n \lg n)</span>.</p><h1>Lecture 3</h1>

  <!--
<header id="title-block-header">
<h1 class="title">Lecture 3 — Graphs</h1>
<p class="author">Kenton Lam</p>
<p class="date">2020-08-18</p>
</header>
-->


<h1 id="lecture-3-graphs">Lecture 3 — Graphs</h1>
<p>A <strong>graph</strong> is made up of <em>vertices</em> and <em>edges</em> between pairs of vertices.</p>
<figure>
<img src="/assets/image-20200818081442148.png" alt="" /><figcaption>image-20200818081442148</figcaption>
</figure>
<p>Graphs can be used to represent a range of scenarios, including maps, networks, brains, and program control flow.</p>
<p>A graph can be directed or undirected.</p>
<h2 id="undirected-graph">Undirected graph</h2>
<ul>
<li>No self-loops.</li>
<li><span class="math inline">(u, v) \in E(G)</span> means <span class="math inline">v</span> is <strong>adjacent</strong> to <span class="math inline">u</span> and this is symmetric.</li>
<li>We also say <span class="math inline">(u, v)</span> is <strong>incident</strong> <strong>on</strong> <span class="math inline">v</span> and <span class="math inline">u</span>.</li>
<li>The <strong>degree</strong> of a vertex is the number of adjacent edges.</li>
</ul>
<h2 id="directed-graph">Directed graph</h2>
<ul>
<li>Can have self-loops.</li>
<li><span class="math inline">(u, v) \in E(G)</span> means <span class="math inline">v</span> is <strong>adjacent</strong> to <span class="math inline">u</span> and this is not symmetric.</li>
<li>We also say <span class="math inline">(u, v)</span> is <strong>incident from</strong> <span class="math inline">u</span> and <strong>incident to</strong> <span class="math inline">v</span>.</li>
<li>The <strong>out-degree</strong> is the number of edges leaving it.</li>
<li>The <strong>in-degree</strong> is the number of edges entering it.</li>
<li>The <strong>degree</strong> is the sum of in- and out-degrees.</li>
</ul>
<p>Note that the maximum edges in a directed graph is <span class="math inline">n^2</span>, and <span class="math inline">n(n-1)/2</span> for an undirected graph.</p>
<h2 id="weights">Weights</h2>
<p>Another key property of graphs is weights. An edge (directed or undirected) can have weights. This can represent something like distance, similarity, or cost. In a social media friends network, this might be the number of mutual friends.</p>
<h2 id="terminology">Terminology</h2>
<p>A graph <span class="math inline">G</span> is:</p>
<ul>
<li>A <strong>path</strong> of length <span class="math inline">k</span> from <span class="math inline">v_0</span> to <span class="math inline">v_k</span> is a sequence <span class="math inline">\langle v_0, \ldots, v_k\rangle</span> such that <span class="math inline">(v_{i-1}, v_i) \in E</span> for <span class="math inline">i=1, \ldots, k</span>.</li>
<li><span class="math inline">u</span> is <strong>reachable</strong> from <span class="math inline">v</span> if there is any path from <span class="math inline">v</span> to <span class="math inline">u</span>.</li>
<li>A path is <strong>simple</strong> if all vertices in the path are distinct.</li>
<li>A path is a <strong>cycle</strong> if <span class="math inline">v_0=v_k</span> and <span class="math inline">k&gt;1</span> (i.e. not a self-loop).</li>
<li>A cycle is <strong>simple</strong> if it is distinct except for its ends.</li>
<li>A graph with no simple cycles is called <strong>acyclic</strong>.</li>
</ul>
<p>An undirected graph <span class="math inline">G</span> is</p>
<ul>
<li><strong>connected</strong> if every vertex is reachable from any other,</li>
<li>a <strong>forest</strong> if it is acyclic, and</li>
<li>a <strong>tree</strong> if it is a forest with only one connected component.</li>
</ul>
<p>Note that for an undirected graph with <span class="math inline">n</span> vertices, a tree must have <span class="math inline">n-1</span> edges, and a forest can have <span class="math inline">0</span> to <span class="math inline">n-1</span> vertices. In a connected undirected graph, the minimum edges is <span class="math inline">n-1</span> and the maximum is <span class="math inline">n(n-1)/2</span> because we must have connections and the maximum is an arithmetic series.</p>
<p>A directed graph <span class="math inline">G</span> is</p>
<ul>
<li><strong>strongly connected</strong> if any two vertices are reachable from each other.</li>
</ul>
<p>A graph <span class="math inline">G&#39;=(V&#39;, E&#39;)</span> is</p>
<ul>
<li>a <strong>subgraph</strong> of <span class="math inline">G=(V,E)</span> if <span class="math inline">V&#39; \subseteq V</span> and <span class="math inline">E&#39;\subseteq E</span>, and</li>
<li>a <strong>spanning subgraph</strong> if it is a subgraph and <span class="math inline">V&#39;=V</span>.</li>
</ul>
<p>The subgraph of <span class="math inline">G</span> which is <strong>induced by <span class="math inline">V&#39;</span></strong> is <span class="math inline">G&#39;=(V&#39;, E&#39;)</span> where <span class="math inline">E&#39;=\{(u, v) \in E : u \in V&#39; \wedge v \in V&#39;\}</span>. That is, it has all edges which start and end in <span class="math inline">V&#39;</span>.</p>
<h2 id="types-of-graphs">Types of graphs</h2>
<ul>
<li>Directed acyclic graph (DAG)</li>
<li>Connected graph</li>
<li>Trees</li>
<li>Lists can also be seen as simple graphs (see linked lists)</li>
</ul>
<h2 id="representations">Representations</h2>
<p>There are two main ways to represent graphs while programming:</p>
<ul>
<li>adjacency lists, and</li>
<li>adjacency matrices.</li>
</ul>
<p>Representing the sets of vertices and edges directly is often inefficient.</p>
<h3 id="adjacency-list">Adjacency list</h3>
<p>For undirected graphs,</p>
<ul>
<li>the worst-case space complexity is <span class="math inline">\Theta(v + \sum_{v}\operatorname{degree}(v))=\Theta(v+2e) \in \Theta(v+e)</span>,</li>
<li>the time complexity of <span class="math inline">\operatorname*{isAdjacentTo}(u, v)</span> is <span class="math inline">\Theta(v)</span>, and</li>
<li>the time complexity of listing all adjacent vertex pairs is <span class="math inline">\Theta(v+e)</span>.</li>
</ul>
<p>Similarly for directed graphs,</p>
<ul>
<li>the space complexity is <span class="math inline">\Theta(v+e)</span>,</li>
<li>the time complexity if <span class="math inline">\operatorname*{isAdjacentTo}</span> is <span class="math inline">\Theta(v)</span>, and</li>
<li>listing adjacent vertex pairs is <span class="math inline">\Theta(v+e)</span>.</li>
</ul>
<p>However, in this case, the bounds make use of <span class="math inline">\operatorname*{outDegree}</span> instead of just <span class="math inline">\operatorname*{degree}</span> in the derivation.</p>
<h3 id="adjacency-matrix">Adjacency matrix</h3>
<p>An adjacency matrix is a <span class="math inline">v \times v</span> matrix where the <span class="math inline">i,j</span>-th entry indicates if there is an edge from <span class="math inline">i</span> to <span class="math inline">j</span>.</p>
<p>For undirected graphs, the matrix will be symmetric, and</p>
<ul>
<li>the space complexity is <span class="math inline">\Theta(v^2)</span>,</li>
<li>the time complexity of <span class="math inline">\operatorname*{isAdjacentTo}</span> is <span class="math inline">\Theta(1)</span> (because we only check the specific cell), and</li>
<li>the time complexity of listing all adjacent vertex pairs is <span class="math inline">\Theta(v^2)</span>.</li>
</ul>
<p>Note that the optimal representation depends very much on the type of operations we expect to do and the properties of the graphs.</p>
<p>For a directed graph, the complexities are the same but the matrix may be asymmetric.</p>
<h3 id="comparison-of-adjacency-list-and-adjacency-matrix">Comparison of adjacency list and adjacency matrix</h3>
<p>The adjacency list is often more efficient if the graph is sparse, and matrix is better if the graph is dense.</p>
<h2 id="graph-traversal-algorithms">Graph traversal algorithms</h2>
<p>For an unweighted graph <span class="math inline">G</span>,</p>
<ul>
<li>the <strong>length of a path</strong> is the number of edges in that path,</li>
<li>the <strong>distance</strong> from <span class="math inline">u</span> to <span class="math inline">v</span> is the shortest path length from <span class="math inline">u</span> to <span class="math inline">v</span>.</li>
</ul>
<h3 id="breadth-first-search">Breadth-first search</h3>
<p><strong>Breadth-first search</strong> (BFS) takes an unweighted graph and a start vertex <span class="math inline">v_0</span>. It traverses vertices within <span class="math inline">G</span> in order of their distance from <span class="math inline">v_0</span>. It is able to find the shortest path from <span class="math inline">v_0</span> to every other vertex in the graph.</p>
<h4 id="implementation">Implementation</h4>
<p>This can be implemented using a queue (FIFO) data structure, which has operations enqueue and dequeue.</p>
<p>We augment the vertex type with distance, state, and parent fields. The parent fields will be used to obtain the shortest path.</p>
<h3 id="depth-first-search">Depth-first search</h3>
<p>Depth-first search (DFS) does not find the shortest path, but is often used as a subroutine in other algorithms.</p>
<p>It visits a vertex <span class="math inline">v</span> then visiting all unvisited adjacent vertices <span class="math inline">u</span> to <span class="math inline">v</span>.</p>
<p>It has complexity <span class="math inline">\Theta(v) + (\sum_{v}(\Theta(1) + \operatorname*{outDegree}(v)\Theta(1)))=\Theta(v+e)</span>.</p>
<h2 id="topological-sort">Topological sort</h2>
<p>To implement topological sort, we can DFS and add vertices to the end of the list when it has no further unvisited neighbours.</p><h1>Lecture 4</h1>

  <!--
<header id="title-block-header">
<h1 class="title">Lecture 4 — Graphs 2</h1>
<p class="author">Kenton Lam</p>
<p class="date">2002-08-25</p>
</header>
-->


<h1 id="lecture-4-graphs-2">Lecture 4 — Graphs 2</h1>
<blockquote>
<p>The midsemester exam will be on 15th September.</p>
</blockquote>
<p>Recall graphs are used to represent a great many problems. They may be directed/undirected and weighted/unweighted.</p>
<p>They can be represented (most commonly) by an adjacency list or an adjacency matrix.</p>
<p>Two search methods are BFS and DFS. BFS is able to find shortest distances from a graph. DFS can be used as a subroutine.</p>
<h2 id="minimum-spanning-tree">Minimum Spanning Tree</h2>
<p>Suppose you are laying cable and want to connect some houses using the least amount of cable possible. This is exactly a minimum spanning tree problem.</p>
<p>Suppose we have a connected, undirected, weighted graph <span class="math inline">G=(V, E)</span> and weights <span class="math inline">w(u, v)</span> denoting the weight between <span class="math inline">u</span> and <span class="math inline">v</span>. We want to find an acyclic subset <span class="math inline">T \subseteq E</span> such that</p>
<ul>
<li>all vertices in <span class="math inline">G</span> are connected, and</li>
<li>the total weight of <span class="math inline">T</span>, <span class="math inline">\sum w(u, v)</span> is minimised.</li>
</ul>
<p>Specifically, <span class="math inline">T</span> is a <strong>tree</strong> (a connected acyclic subgraph of <span class="math inline">G</span>) that <strong>spans</strong> (contains all vertices in <span class="math inline">G</span>) and <strong>minimises</strong> the sum of edge weights.</p>
<h2 id="generic-constructive-algorithm">Generic Constructive Algorithm</h2>
<p>Start with an empty set for <span class="math inline">T</span> and while <span class="math inline">T</span> is not a spanning tree, find an edge which can be added to <span class="math inline">T</span> (i.e. does not create any cycles) and add it.</p>
<h2 id="prims-algorithm">Prim’s Algorithm</h2>
<p>Here, <span class="math inline">T</span> is always a tree. Start at any vertex (this will be our initial <span class="math inline">T</span>). Repeatedly add the least-weight edge leaving the constructed tree <span class="math inline">T</span>. For each edge leaving the adjacent vertex, we update that in a priority queue. The algorithm stops when <span class="math inline">T</span> is a spanning tree, i.e. contains every vertex from <span class="math inline">G</span>.</p>
<p>How can we find the least-weight edge leaving <span class="math inline">T</span>?</p>
<ul>
<li>Maintain a priority queue <span class="math inline">Q</span> containing vertices <span class="math inline">V-T</span>. For each vertex in this queue, its key is the minimum edge weight connecting it to <span class="math inline">T</span>. Additionally, its parent is the vertex adjacent along this least-weight edge.</li>
<li>Recall that a priority queue’s operations are insert, extractMin, and decreaseKey.</li>
</ul>
<h2 id="kruskals-algorithm">Kruskal’s Algorithm</h2>
<p>Also used to find a minimum spanning tree. Here, <span class="math inline">T</span> is always a spanning acyclic subgraph, a <em>forest</em> of trees. Initially, <span class="math inline">T</span> is all vertices but no edges.</p>
<p>At each step, the least-weight edge connecting two trees in <span class="math inline">T</span> is added to the forest. We repeat this process until <span class="math inline">T</span> is connected.</p>
<p>The trees in <span class="math inline">T</span> are represented using a disjoint set data structure. Each set has a representative element from that set. Its operations are makeSet, findSet, and union. These disjoint sets are represented by rooted trees, and the representative element is the root of the tree. Each element in these trees stores a pointer to its parent (or itself if it is the root) and a rank (an upper bound on the node’s height in the tree).</p>
<ul>
<li><p>makeSet just creates a new single-node tree. Its parent will be the node itself and its rank is zero.</p></li>
<li><p>findSet returns the root of the tree. To make this fast, it collapses the path from (grand)children to point directly to the root.</p>
<figure>
<img src="/assets/image-20200825092403249.png" alt="" /><figcaption>image-20200825092403249</figcaption>
</figure></li>
<li><p>union works by linking the representative elements of its arguments. The subtree with greater rank is used as the combined representative element. If they have the same rank, choose arbitrarily but increment the final rank.</p>
<figure>
<img src="/assets/image-20200825092746558.png" alt="" /><figcaption>image-20200825092746558</figcaption>
</figure>
<figure>
<img src="/assets/image-20200825092759020.png" alt="" /><figcaption>image-20200825092759020</figcaption>
</figure></li>
</ul>
<h3 id="pseudocode">Pseudocode</h3>
<ul>
<li>Start by making disjoint sets for each vertex.</li>
<li>Order all edges ascending by weight.</li>
<li>For each edge <span class="math inline">(u, v)</span> in this sorted list:
<ul>
<li>If the set of <span class="math inline">u</span> is not the set of <span class="math inline">v</span>, add <span class="math inline">(u, v)</span> to <span class="math inline">T</span> and union the sets.</li>
</ul></li>
<li>After iterating through all edges, <span class="math inline">T</span> is our minimum spanning tree.</li>
</ul><h1>Lecture 5</h1>

  <!--
<header id="title-block-header">
<h1 class="title">Lecture 5 — Graph Algorithms 2</h1>
<p class="author">Kenton Lam</p>
<p class="date">2020-09-08</p>
</header>
-->


<h1 id="lecture-5-graph-algorithms-2">Lecture 5 — Graph Algorithms 2</h1>
<p>Recall the shortest path is a sequence of vertices from a particular start to a particular end. The total weight of the path is the sum of all edge paths.</p>
<p>There are several types:</p>
<ul>
<li>Single pair: the shortest path between two given vertexes <span class="math inline">(u, v)</span>.</li>
<li>Single source: Given a vertex <span class="math inline">v</span>, find shortest paths to every other vertex.</li>
<li>Single destination: Given a destination <span class="math inline">v</span>, find shortest paths <em>from</em> every other vertex.</li>
<li>All pairs: Find the shortest path between every pair of vertices.</li>
</ul>
<h2 id="single-source-shortest-path">Single source shortest path</h2>
<p>Given a graph <span class="math inline">G</span> with weight function <span class="math inline">w</span> and source <span class="math inline">s</span>, for each <span class="math inline">v \in G.V</span>, we need to calculate</p>
<ul>
<li><span class="math inline">v.d</span>, its distance from <span class="math inline">s</span>, and</li>
<li><span class="math inline">v.\pi</span>, its predecessor from a shortest path from <span class="math inline">s</span> to <span class="math inline">v</span>.</li>
</ul>
<ol type="1">
<li>We initialise <span class="math inline">s.d=0</span> and <span class="math inline">v.d=\infty</span> else. The invariant here is that the shortest distance from <span class="math inline">s</span> to <span class="math inline">v</span> is less than or equal to <span class="math inline">v.d</span> less than or equal to <span class="math inline">\infty</span>.</li>
<li>Initialise all <span class="math inline">v.\pi = \textit{null}</span>.</li>
<li>Perform a relaxation on the distance estimates until we reach a solution.</li>
</ol>
<h3 id="relax">Relax</h3>
<p>This checks if we can reach <span class="math inline">v</span> (from <span class="math inline">s</span>) sooner by going through <span class="math inline">u</span>. If so, we reduce the distance and update the predecessor.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a><span class="kw">def</span> relax(u, v, w):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a>  <span class="cf">if</span> v.d <span class="op">&gt;</span> u.d <span class="op">+</span> w(u, v):</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true"></a>    v.d <span class="op">=</span> u.d <span class="op">+</span> w(u, v)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true"></a>    v.pi <span class="op">=</span> u</span></code></pre></div>
<p>Note that this preserves the distance and predecessor invariants as this only changes if a better path is found.</p>
<h2 id="non-negative-weights">Non-negative weights</h2>
<p>If <span class="math inline">p_n = v_1 \to v_2 \to \cdots \to v_n</span> is a shortest path from <span class="math inline">v_1</span> to <span class="math inline">v_n</span> in a graph with no negative weights, then for all <span class="math inline">1 \le i \le n-1</span>, the prefix <span class="math display">
p_1 = v_1 \to \cdots \to v_i
</span> is in fact a shortest path from <span class="math inline">v_1</span> to <span class="math inline">v_i</span> and we must have <span class="math inline">\operatorname{weight}(p_i) \le \operatorname{weight}(p_n)</span>. This does not hold if some edges have negative weights! There might be edges of negative weight between <span class="math inline">p_i</span> and <span class="math inline">p_n</span>.</p>
<h2 id="dijkstras-algorithm">Dijkstra’s algorithm</h2>
<p>Solves the single-source shortest paths problem for non-negative weighted graphs. A more sophisticated variant called A* is commonly used in computer games.</p>
<ol type="1">
<li>Initialise <span class="math inline">s.d=0</span> and <span class="math inline">v.d=\infty</span> otherwise. Distance invariant is the same.</li>
<li>Initialise <span class="math inline">v.\pi=\textit{null}</span>. Predecessor invariant.</li>
<li>Visit each vertex in order of its distance from the source. For each outgoing edge, we relax along that edge.</li>
</ol>
<p>This is a generalisation of breadth first search to weighted graphs.</p>
<p>How can we efficiently find the next vertex to visit? Let <span class="math inline">S</span> be the set of visited vertices. We will maintain <span class="math inline">Q</span>, a priority queue of vertices <span class="math inline">V-S</span> keyed by <span class="math inline">v.d</span>.</p>
<p>This runs in <span class="math inline">O(E \lg V)</span> with a binary heap or <span class="math inline">O(E + V \lg V)</span> for a Fibonacci heap.</p>
<figure>
<img src="/assets/image-20200908090847384.png" alt="" /><figcaption>image-20200908090847384</figcaption>
</figure>
<h3 id="intuition">Intuition</h3>
<p>When we visit a vertex, we know that we have found the shortest path to <span class="math inline">u</span>. This means the predecessor <span class="math inline">v</span> of <span class="math inline">u</span> may have smaller distance, in which case we already visited it, or equal distance, in which case we have already found a shortest path to <span class="math inline">u</span> with the same length.</p>
<h2 id="negative-weights">Negative weights</h2>
<p>What if we had negative weights? Dijkstra’a algorithm might not relax edges in the correct order. That is, <span class="math inline">(u, v)</span> might be relaxed before we have a shortest path to <span class="math inline">u</span> so this relaxation would be incorrect.</p>
<p>Is the shortest path even well-defined for graphs with negative weight cycles? No, because we can just keep going around that negative cycle to reduce the weight.</p>
<p>Here is an example without negative weight cycles where Dijkstra’s algorithm fails. This goes in order <span class="math inline">a, c, d, b</span> which cannot find the correct shortest path.</p>
<figure>
<img src="/assets/image-20200908092238718.png" alt="" /><figcaption>image-20200908092238718</figcaption>
</figure>
<p>There are two problems here: we need to avoid negative weight cycles, and we need to relax in the correct order.</p>
<h2 id="bellman-ford">Bellman-Ford</h2>
<p>After initialisation, we have found all shortest paths which contain <span class="math inline">\le 0</span> edges. After relaxing each edge once, we have found all shortest paths containing <span class="math inline">\le 1</span> edges. Relaxing all the edges again finds shortest paths of length <span class="math inline">\le 2</span>. Continuing to <span class="math inline">V-1</span> times, we have all shortest paths containing <span class="math inline">\le V-1</span> edges.</p>
<p>The Bellman-Ford algorithm uses this to find single-source shortest paths on directed graphs which may contain negative weight edges. Additionally, it detects negative weight cycles and is able to return false if one is found.</p>
<figure>
<img src="/assets/image-20200908092800492.png" alt="" /><figcaption>image-20200908092800492</figcaption>
</figure>
<p>If there is a negative weight cycle, then even going through <span class="math inline">V-1</span> times is not enough to reduce the shortest path length to minimum. This is because <span class="math inline">V-1</span> is the maximum length of a shortest path with no cycles. We go through the edges once more and if we find another decrease (i.e. another shortest path), we return false.</p>
<p>This algorithm has time complexity <span class="math inline">O(V E)</span>, because it goes through the edges <span class="math inline">V-1</span> times. The worst-case of this is a fully connected graph where <span class="math inline">E=V^2</span>.</p>
<p>This is a generalisation of Dijkstra’s algorithm but runs in much slower time. Is there a more efficient way to find single-source shortest path if the graph is acyclic?</p>
<h2 id="priority-first-search">Priority first search</h2>
<p>This is a generalisation including Dijkstra’s algorithm and Prim’s algorithm for MST.</p>
<p>Vertices are visited in order of <em>priority</em> (for some definition of priority function). For example, the priority could be the weight (as in Prim’s) or the cumulative distance (as in Dijkstra’s).</p>
<figure>
<img src="/assets/image-20200908093707791.png" alt="" /><figcaption>image-20200908093707791</figcaption>
</figure>
    <p><small>Generated at 9/13/2020, 1:19:15 AM.</small></p>
  </body>
</html>
